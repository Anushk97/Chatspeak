title,link,snippet
What Language Model Architecture and Pretraining Objective ...,https://proceedings.mlr.press/v162/wang22u.html,"Abstract. Large pretrained Transformer language models have been shown to exhibit zero-shot generalization, i.e. they can perform a wide variety of tasks that ..."
Sketching Transformed Matrices with Applications to Natural ...,https://proceedings.mlr.press/v108/liang20a.html,"Many machine learning applications indeed need to deal with such large transformed matrices, for example word embedding method in NLP needs to work with the ..."
Retrieval Augmented Language Model Pre-Training,https://proceedings.mlr.press/v119/guu20a.html,"To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model ..."
How could Neural Networks understand Programs?,https://proceedings.mlr.press/v139/peng21b.html,"How could Neural Networks understand Programs?Dinglan Peng, Shuxin Zheng, Yatao Li, Guolin Ke, Di He, Tie-Yan LiuSemantic understand..."
Calibration of Natural Language Understanding Models with ...,https://proceedings.mlr.press/v179/giovannotti22a/giovannotti22a.pdf,We test their performance over a set of diverse NLU tasks and show that they are capable of producing well-calibrated probabilistic predictions that are ...
Large Language Models Can Be Easily Distracted by ...,https://proceedings.mlr.press/v202/shi23a.html,%0 Conference Paper %T Large Language Models Can Be Easily Distracted by Irrelevant Context %A Freda Shi %A Xinyun Chen %A Kanishka Misra %A Nathan Scales %A ...
Towards Understanding Situated Natural Language,https://proceedings.mlr.press/v9/bordes10a.html,Our method allows both world knowledge and linguistic information to be used during learning and prediction. We show experimentally that we can learn to use ...
A journey into the Generative AI and large language models,https://proceedings.mlr.press/v217/elnaggar23a.html,"Abstract. In the last year, the generative AI field has seen a remarkable breakthrough, specifically the generative ai models and their ..."
The Natural Language of Actions,https://proceedings.mlr.press/v97/tennenholtz19a.html,"The Natural Language of ActionsGuy Tennenholtz, Shie MannorWe introduce Act2Vec, a general framework for learning context-based action representation fo..."
Efficient Training of Language Models using Few-Shot Learning,https://proceedings.mlr.press/v202/j-reddi23a.html,"We show that, by leveraging the fast learning nature of few-shot learners, one can train language models efficiently in a stagewise manner. Our main ..."
