title,link,snippet
TabLLM: Few-shot Classification of Tabular Data with Large ...,https://proceedings.mlr.press/v206/hegselmann23a/hegselmann23a.pdf,Large Language Models For Classification TabLLM can be used with different LLMs that generate text based on a natural-language input. Let LLM be an LLM with.
Zero-Shot ECG Diagnosis with Large Language Models and ...,https://proceedings.mlr.press/v225/yu23b/yu23b.pdf,"Moreover, previous LLM-based studies inferred. ECG conditions by fine-tuning the prompts that per- form the diagnosis process primarily using the in- trinsic ..."
Large Language Models Struggle to Learn Long-Tail ...,https://proceedings.mlr.press/v202/kandpal23a/kandpal23a.pdf,"In this work, we explore the relationship between the knowl- edge learned by an LLM and the information in its pre- training dataset. Specifically, we study how ..."
Extracting Actionable Knowledge for Embodied Agents,https://proceedings.mlr.press/v162/huang22a/huang22a.pdf,"Can world knowledge learned by large language models (LLMs) be used to act in interactive envi- ronments? In this paper, we investigate the pos-."
Prompting Large Language Model for Machine Translation,https://proceedings.mlr.press/v202/zhang23m/zhang23m.pdf,"Setting We experiment with GLM-130B, a LLM with. 130B parameters pretrained on Chinese and English “mono- lingual” corpora, which was reported to outperform GPT ..."
PAL: Program-aided Language Models,https://proceedings.mlr.press/v202/gao23f.html,"In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM ... LLM, while solving is delegated to the interpreter. We ..."
Scaling Up and Distilling Down: Language-Guided Robot Skill ...,https://proceedings.mlr.press/v229/ha23a/ha23a.pdf,"For (1), we use a large language model (LLM) to guide high-level planning, and sampling-based robot planners. (e.g. motion or grasp samplers) for generating ..."
Embodied Decision Making using Language Guided World ...,https://proceedings.mlr.press/v202/nottingham23a/nottingham23a.pdf,"We propose using few-shot large language models. (LLMs) to hypothesize an AWM, that will be veri- fied through world experience, to improve sample efficiency of ..."
Grounding Large Language Models in Interactive ...,https://proceedings.mlr.press/v202/carta23a/carta23a.pdf,Recent works successfully leveraged Large Lan- guage Models' (LLM) abilities to capture ab- stract knowledge about world's physics to solve.
Automated LOINC Standardization Using Pre-trained Large ...,https://proceedings.mlr.press/v193/tu22a/tu22a.pdf,"Our approach, on the other hand, uses embeddings from pre-trained LLM to extract features from text strings, avoid- ing the need for manual feature engineering."
Can Large Language Models Reason about Program ...,https://proceedings.mlr.press/v202/pei23a/pei23a.pdf,"fine-tune an LLM, pre-trained on source code, to take as input the source code of a program, and a target program point, and to output a list of invariants ..."
LLMs Accelerate Annotation for Medical Information Extraction,https://proceedings.mlr.press/v225/goel23a/goel23a.pdf,"Initially, the LLM, conditioned in a few-shot learning setup, generates Base Annota- tions. Subsequently, these annotations are refined by medical annotation ..."
Parallel Diverse Decoding for Large Language Models,https://proceedings.mlr.press/v202/vilnis23a/vilnis23a.pdf,An even lattice of code points parallelizes decoding into diverse high-probability sequences. options for inference are limited. While LLM inference can be ...
Language Models as Zero-Shot Planners: Extracting ...,https://proceedings.mlr.press/v162/huang22a.html,Our evaluation in the recent VirtualHome environment shows that the resulting method substantially improves executability over the LLM baseline. The ...
Deja Vu: Contextual Sparsity for Efficient LLMs at Inference ...,https://proceedings.mlr.press/v202/liu23am/liu23am.pdf,"Spar- sity is a natural approach to reduce this cost, but existing methods either require costly retraining, have to forgo LLM's in-context learning ability, or."
Do Embodied Agents Dream of Pixelated Sheep,https://proceedings.mlr.press/v202/nottingham23a.html,Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a ...
Reprogramming Pretrained Language Models for Antibody ...,https://proceedings.mlr.press/v202/melnyk23a/melnyk23a.pdf,"Moreover, the sequence-based mod- els typically involve LLM training from scratch on NGS repertoire (Olsen et al., 2022), or GNN training on a small sample ..."
Less is More: Task-aware Layer-wise Distillation for Language ...,https://proceedings.mlr.press/v202/liang23j/liang23j.pdf,"For example, a possible strategy is to use a LLM teacher to generate task-relevant input and output samples in a controllable manner, and then use these samples ..."
Grounding Large Language Models in Interactive ...,https://proceedings.mlr.press/v202/carta23a.html,"In this paper, we study an approach (named GLAM) to achieve this alignment through functional grounding: we consider an agent using an LLM as a policy that ..."
